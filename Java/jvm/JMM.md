# JMM

Java并发的通信机制是通过共享内存实现的。线程之间共享程序的公共状态，线程通过读写内存中的公共状态进行隐式通讯。这对程序员是透明的，我们需要理解其工作机制，以防止内存可见性问题，从而编写出正确同步的代码。

**同步**：当有一个线程在对内存进行操作时，其他线程都不可以对这个内存地址进行操作，直到该线程完成操作。

**内存可见性问题**：java中线程通过共享变量的方式进行通讯，那么一个线程要跟另外一个线程进行通讯，什么时候将这个共享变量刷新到内存；另外一个线程什么时候该去内存中读取。这就是内存可见性问题。JMM就是解决这个问题的。

内存可见性问题，**就是一个线程更新共享变量后，其他线程无法看到该共享变量最新的值。这就是内存可见性问题。**



## JMM

Java内存模型，决定了一个线程对共享变量的写入何时对另外一个线程可见。有两点需要注意：

- 这里何时指的并非时间而是某个动作的完成。有哪些动作呢？
  - 当写一个volatile变量时，JMM会把该线程对应的本地内存中的共享变量值刷到主内存中，同时使其它处理器中的缓存失效，让其去主内存中读取该值；
  - 还有synchronized的锁释放，CAS操作。
- 同步是显式的，是需要我们来做的。JMM对未同步或未正确同步的多线程程序只提供最小的安全性，也就是JMM保证线程读取到的值不会无中生有，要么是之前线程写入的值，要么是默认值（0，null，false）。



首先来看下JMM下线程与主内存之间的关系问题。共享变量在主内存中，每个线程都有一个自己私有的本地内存，里面存储着内存中共享变量的副本。

**本地内存是对缓存、写缓冲区、寄存器等的抽象**

来看看JMM的抽象结构示意图:

![image-20191012153824636](https://tva1.sinaimg.cn/large/006y8mN6gy1g7vgi4wlpxj30h40fb773.jpg)

假设两个线程A，B。

A将其更新后的共享变量刷新到主内存，B到主内存中去读取该共享变量的值，实质上就是**线程A在向线程B发送消息**，基于的是主内存，JMM控制的就是主内存与每个线程的本地内存的交互。上面说Java线程间通信机制是隐式的，对程序员不可见，那么JMM就为我们提供了内存可见性的保证，对于正确同步的代码（指的是synchronized,volatile,final的运用），我们就可以得到正确的执行结果。



## 重排序



###**关于重排序**

重排序是指**编译器和处理器为了优化程序性能，而对指令序列进行重新排序**

重排序分为3种类型：

- 编译器优化的重排序
  - 如果不存在数据依赖性，编译器可以重新安排语句的执行顺序
- 指令级并行的重排序
  - 现代处理器采用了指令级并行技术，可以将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应指令的执行顺序。
- 内存系统的重排序
  - 指的是处理器在执行指令时，使用缓存和读写缓冲区。使得指令看起来不是顺序执行的。
  - ![image-20191111232800659](https://tva1.sinaimg.cn/large/006y8mN6gy1g8uiny6djfj31i60gc44k.jpg)



从Java源代码到最终执行的指令，会经历下面3种重排序：

![image-20191111231113768](https://tva1.sinaimg.cn/large/006y8mN6gy1g8ui6hglngj31iq06u0wx.jpg)



编译器、处理器重排序，导致多线程的程序出现内存可见性的问题。

- 对于编译器，**JMM编译器重排序的规则**会禁止特定类型的重排序
- 对于处理器重排序，**Java编译器在生成指令序列的适当位置 插入特定类型的内存屏障**指令，来禁止特定类型的处理器重排序

JMM就是通过此来确保在不同的编译器和处理器平台上的内存可见性保证。





### 数据依赖性

两个操作访问同一个变量，且至少有一个为写操作，则二者之间存在数据依赖性。

![image-20191112130608277](https://tva1.sinaimg.cn/large/006y8mN6gy1g8v6b7nmk2j30s108x0ui.jpg)

编译器与处理器不会改变存在数据依赖关系的两个操作的执行顺序，因为对它们的重排序会改变程序的执行结果。

注意：数据依赖性指的是单个处理器的指令序列和单个线程中执行的操作，**不同处理器和不同线程之间的数据依赖性不被考虑**。也就是说，不同线程和不同处理器的指令不干扰，可以进行重排序。





### **关于内存屏障**

![image-20191012155729906](https://tva1.sinaimg.cn/large/006y8mN6gy1g7vh1ybnqmj30nc08zwj3.jpg)

StoreLoader 屏障同时具有其它三个屏障的效果。执行该屏障开销会很昂贵，因为当前处理器通常要把写缓冲区的数据全部刷到内存中。

volatile的内存语义，final的内存语义都是通过上述内存屏障来实现的。

**针对重排序，JMM的基本方针就是：在不改变正确同步的程序的执行结果的前提下，尽可能为编译器和处理器的优化打开方便之门。**



### as-if-serial

as-if-serial的意思是：不管怎么重排序，（单线程）程序的执行结果不能被改变。编译器和处理器必须遵守as-if-serial语义。

为了遵守as-if-serial语义，编译器和处理器不会对存在数据依赖关系的操作做重排序，因为这种重排序会改变执行结果。但是，如果操作之间不存在数据依赖关系，那么这些操作就可能被编译器和处理器做重排序。

as-if-serial把单线程程序保护起来。



### 重排序对多线程的影响

```java
public class ReorderExample {

    int a = 0;

    boolean flag = false;

    public void writer() {
        a = 1;              // 1

        flag = true;        // 2
    }

    public void reader() {

        if (flag) {         // 3

            int i = a * a;  // 4
        }
    }
}
```

当一些操作不存在数据依赖性，可以进行重排序，但是如果还存在控制依赖性，进行重排序可能就会影响程序执行结果，比如上面的操作3和操作4交换执行顺序，就会使结果出错。但是控制依赖性又会导致并行度降低。

编译器和处理器为了提高并行度，使用**猜测执行**来克制控制依赖性对并发度的影响。以处理器猜测执行为例，该线程的处理器可以提前读取a，并且计算a*a的值，然后把结果放到**重排序缓冲**中。当操作3的条件判断为真，就把结果写入到变量i中。

**在单线程程序中，对存在控制依赖关系的操作重排序，不会改变程序的执行结果。**比如writer()和reader()函数在单线程中顺序执行，即1234操作顺序执行，并且1和2 happen-before 3和4。于是1和2、3和4可以重排序，但是不影响程序执行结果。

**但是在多线程程序中，对存在控制依赖关系的操作重排序，可能会改变程序的执行结果**。比如writer()在线程A中执行，reader()在线程B中执行，1和2不存在数据依赖性，3和4不存在数据依赖性。因此1和2可以进行重排序，3和4由于存在控制依赖性，使用猜测执行。假如经过重排序之后，执行顺序为 2431，那么i的结果为0。这就改变了程序的执行结果。





## 顺序一致性

如果程序是正确同步的，程序的执行将具有顺序一致性——即程序的执行结果与程序在顺序一致性内存模型中的执行结果相同。



### 顺序一致性内存模型

顺序一致性内存模型是一个理论参考模型，它为程序员提供了极强的内存可见性保证。顺序一致性模型的特征：

- **一个线程中所有操作必须按照程序的顺序来执行**
- 不管程序是否同步，**所有线程都只能看到一个单一的操作执行顺序**，
- 每个操作必须原子执行，并且立刻对所有线程可见

顺序一致性模型为程序员提供的视图如下：

![image-20191113232359329](https://tva1.sinaimg.cn/large/006y8mN6gy1g8wtsfiojtj311b0u0tf4.jpg)

在概念上，顺序一致性模型有一个单一的全局内存，这个内存通过一个左右摆动的开关可以连接到任意一个线程，同时每一个线程必须按照程序的顺序来执行内存读/写操作。在任意时间点最多只能有一个线程可以连接到内存。

**在JMM中就没有这个保证。未同步程序在JMM中不但整体的执行顺序是无序的，而且所有线程看到的操作执行顺序也可能不一致。**



### 未同步程序的执行特性

对未同步或者未正确同步的程序，JMM提供最小安全性：线程读取到的值，要么之前某个线程写入的值，要么是默认值。

为了实现最小安全性，JVM在堆上分配对象时，首先会对内存空间进行清零，然后才会在上面分配对象，因此，在已清零的内存空间分配对象时，域的默认初始化已经完成了。

未同步程序在两个模型中的执行特征有如下几个差异：

- 顺序一致性模型会保证单线程内的操作会按照程序的顺序执行；而JMM不保证单线程内的操作会按照程序的顺序执行，因为可能会重排序。
- 顺序一致性模型保证所有线程能看到一致的操作执行顺序，而JMM不保证所有线程能看到一致的操作执行顺序。
- JMM不保证对64位long型和double型变量的写操作具有原子性，而顺序一致性模型能保证对所有的内存读/写操作都具有原子性。

第3个差异与处理器总线的工作机制密切相关。在计算机中，数据通过总线在处理器和内存之间传递。每次处理器和内存之间的数据传递都是通过一系列步骤来完成的，这一系列步骤称之为总线事务。

总线事务包括读事务和写事务。

- 读事务从内存传送数据到处理器
- 写事务从处理器传送数据到内存

每个事务会读/写内存中一个或多个物理上连续的字。这里的关键是，总线会同步试图并发使用总线的事务。在一个处理器执行总线事务期间，总线会禁止其他的处理器和I/O设备执行内存的读/写。下面，让我们通过一个示意图来说明总线的工作机制，如下所示。

![image-20191113234650011](https://tva1.sinaimg.cn/large/006y8mN6gy1g8wug5g7ebj30tg0tw46e.jpg)

由图可知，假设处理器A、B和C同时向总线发起总线事务，这时总线仲裁会对竞争做出裁决，这里假设总线在仲裁后判定处理器A在竞争中获胜（总线仲裁会确保所有处理器都能公平的访问内存）。此时处理器A继续他的总线事务，而其他两个处理器则要等待处理器A的总线事务完成后才能再次执行内存访问。假设在处理器A执行总线事务期间（不管这个总线事务是读事务还是写事务），处理器D向总线发起了总线事务，此时处理器D的请求会被总线禁止。

总线的这些工作机制可以把所有处理器对内存的访问以串行化的方式来执行。在任意时间点，最多只能有一个处理器可以访问内存。这个特性确保了单个总线事务之中的内存读/写操作具有原子性。

在一些32位的处理器上，如果要求对64位数据的写操作具有原子性，会有比较大的开销。为了照顾这种处理器，Java语言规范鼓励但不强求JBM对64位的long型变量和double型变量的写操作具有原子性。当JVM在这种处理器上运行时，可能会把一个64位long/double型变量的写操作拆分为两个32位的写操作来执行。这两个32位的写操作可能会被分配到不同的总线事务中执行，此时对这个64位变量的写操作将不具有原子性。

**当单个内存操作不具有原子性**时，可能会产生意想不到后果。请看下面的示意图。

![image-20191113234722254](https://tva1.sinaimg.cn/large/006y8mN6gy1g8wugplykjj30w40iugp9.jpg)



如上图所示，假设处理器A写一个long型变量，同时处理器B要读这个long型变量。处理器A中64位的写操作被拆分为两个32位的写操作，且这两个32位的写操作被分配到不同的写事务中执行。同时处理器B中64位的读操作被分配到单个的读事务中执行。当处理器A和B按上图的时序来执行时，处理器B将看到仅仅被处理器A“写了一半”的无效值。

注意，在JSR-133之前的旧内存模型中，一个64位long/double型变量的读/写操作可以被拆分为两个32位的读/写操作来执行。从JSR-133内存模型开始（即从JDK5开始），仅仅只允许把一个64位long/double型变量的写操作拆分为两个32位的写操作来执行，任意的读操作在JSR-133中都必须具有原子性（即任意读操作必须要在单个读事务中执行）。







## happens-before

用来阐述操作之间的内存可见性。

**如一个操作的执行结果需要对另外一个操作可见，那么这两个操作之间必须存在happens-before关系**

这两个操作可以在一个线程内，也可以在不同线程之间。

happens-before是JMM最核心的概念，程序员基于它的**内存可见性**保证来编程。

![image-20191012212205542](https://tva1.sinaimg.cn/large/006y8mN6gy1g7vqfp71pvj30u00wldui.jpg)

### 定义

1、**如果一个操作发生在另外一个操作之前，第一个操作的结果将对第二个操作可见**

我们也就是依据此保证来理解阅读源码的。

2、**即时两个操作存在happens-before关系，编译器、处理器也不一定按照Happens-Before指定的顺序执行。还是可能进行重排序的，只不过重排序执行的结果和Happens-Before指定顺序执行结果一样就可以了。**



Happens-Before是建立在JMM对重排序的**规则**上的。它保证了即时重排序，正确同步的多线程程序也能得到正确的执行结果。

它给我们这样一种幻觉：正确同步的多线程的程序是按照happens-before指定的顺序来执行的。这里happens-before指定的顺序指的是hannpens-before规则中的**程序顺序规则**，所以我们可以按照代码顺序来阅读代码。



###**hannpens-before规则**

- 程序顺序规则
  - 指的是一个线程中的每个操作，都Happens-Before该线程中任意后续的操作
- 监视器锁的规则
  - 锁的解锁happens-before随后对它的加锁
- volatile变量的规则
  - 对一个volatile域的写happens-before于任意后续对它的读。
- 传递性
  - A happens-before B, B happens-before C，那么A happens-before C



***happens-before不要求前一个操作和后一个操作的发生顺序, 仅仅要求前一个操作的执行完成并刷新回内存发生在后一个操作读取结果之前***



### **happens-before与JMM之间的关系**

![image-20191012233427623](https://tva1.sinaimg.cn/large/006y8mN6gy1g7vu9j43qxj30xo0ruqem.jpg)

一个happens-before规则其背后的实现依赖于多个编译器和处理器的重排序规则，我们不需要去掌握这些复杂的重排序规则及他们的实现，我们只需根据happens-before的规则来编程。



想想自己在阅读JUC下源码时是怎么理解那些正确同步的代码的：

- 我们看到synchronized会想到互斥，锁的释放还会引起共享变量的刷新，一个线程的对锁的释放与随后获取的线程实质上是在通信；
- 看到volatile会想到它的读/写是原子的，且与锁的获取/释放具有相同的内存语义；
- 看到循环CAS想到原子操作，且它具有volatile读/写的内存语义；
- 对于代码的执行顺序我们都默认是按顺序的，我们认为程序是按代码顺序来执行的，可编译器与处理器是会重排序的。
- 那是谁给了你这种保障，让你有这种按顺序执行的幻觉？是JMM，你只要按照happens-before规则来编程，编写的程序是正确同步的，你就可以按顺序来理解它，编译器和处理器的重排序不会影响到你，因为JMM对他们的限制，禁止了那些会改变执行结果的重排序。



### 关于JMM与顺序一致性模型

顺序一致性模型是一个理论参考模型，JMM和处理器内存模型在设计时通常以它为参照。JMM对正确同步的多线程程序的内存一致性做了如下保证：正确同步的程序的执行具有一致性，即程序的执行结果与该程序在顺序一致性内存模型中的执行结果相同。

首先模型有两大特点：

1，一个线程的所有操作必须按照程序的顺序来执行。

2，每个操作必须是原子且立即对所有线程可见，这样所有线程都将看到一个单一的操作执行顺序。



顺序一致性模型下的多线程程序执行情况：

假设有一个正确同步程序，A线程3个操作执行后释放监视器锁，随后B获取该锁执行。其执行效果图：

![image-20191012234115144](https://tva1.sinaimg.cn/large/006y8mN6gy1g7vugkw7c6j311y0mwang.jpg)

对于正确同步程序JMM与顺序一致性模型执行的不同：JMM中临界区内的代码可以重排序，只要不改变程序执行结果。

![image-20191012234156395](https://tva1.sinaimg.cn/large/006y8mN6gy1g7vuh8736vj30xz0u0alo.jpg)









## 参考

https://blog.csdn.net/sinat_34976604/article/details/88762147